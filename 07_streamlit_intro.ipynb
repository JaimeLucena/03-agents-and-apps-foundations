{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "70a144d7",
      "metadata": {},
      "source": [
        "# 07 ‚Äî Intro to Streamlit\n",
        "\n",
        "In this notebook you‚Äôll learn what **Streamlit** is and how to build a **minimal UI** for AI apps.\n",
        "\n",
        "We‚Äôll skip the standalone demo and go straight to connecting Streamlit with a real **FastAPI** backend ‚Äî the cleanest pattern for production-ready prototypes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "debd2754",
      "metadata": {},
      "source": [
        "## üß† What is Streamlit?\n",
        "\n",
        "**Streamlit** is a Python framework for building **simple web apps** with minimal code. It‚Äôs ideal for:\n",
        "- Rapid **prototyping** of AI demos (chat, RAG, agents)\n",
        "- Internal tools and dashboards\n",
        "- Sharing experiments with non-developers\n",
        "\n",
        "You write **pure Python**, and Streamlit turns it into a reactive web UI ‚Äî with widgets like inputs, buttons, and markdown displays ‚Äî no HTML or JavaScript required."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c53381b6",
      "metadata": {},
      "source": [
        "## ‚ö° Why Streamlit for AI apps?\n",
        "\n",
        "- ‚ö° **Fast iteration**: build a working UI in minutes.\n",
        "- üß± **Zero JS**: write everything in Python, Streamlit handles the frontend.\n",
        "- üß™ **Perfect for demos**: quick interfaces for LangChain, LangGraph, or CrewAI apps.\n",
        "- ‚òÅÔ∏è **Easy deployment**: run locally or deploy on Streamlit Cloud, Hugging Face, or similar services.\n",
        "\n",
        "It‚Äôs especially popular for **AI prototypes** ‚Äî combining simplicity, readability, and real-time interactivity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dbaa7fb",
      "metadata": {},
      "source": [
        "## üß© Basic idea\n",
        "\n",
        "A Streamlit app is simply a **Python script** you run with:\n",
        "\n",
        "```bash\n",
        "streamlit run app_streamlit.py\n",
        "```\n",
        "\n",
        "You compose UI elements using functions like:\n",
        "\n",
        "- `st.title(\"My App\")`\n",
        "- `st.text_input(\"Your question\")`\n",
        "- `st.button(\"Submit\")`\n",
        "\n",
        "Each time the user interacts, Streamlit automatically re-runs your script to refresh the interface.\n",
        "\n",
        "Now, let‚Äôs connect Streamlit directly to your **FastAPI** backend to turn this into a live AI chat UI."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7040ee3",
      "metadata": {},
      "source": [
        "## üåê Connecting Streamlit to a FastAPI backend\n",
        "\n",
        "This approach makes Streamlit the **frontend** and FastAPI the **backend**. \n",
        "Streamlit handles the input/output and sends user messages to the FastAPI `/chat` endpoint, which runs your LLM logic (OpenAI, Groq, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e88f7a3",
      "metadata": {
        "name": "app_streamlit_backend.py"
      },
      "outputs": [],
      "source": [
        "# app_streamlit.py ‚Äî Streamlit UI calling a FastAPI /chat endpoint\n",
        "import os\n",
        "import requests\n",
        "import streamlit as st\n",
        "\n",
        "# --- Page setup ---\n",
        "st.set_page_config(page_title=\"Streamlit + FastAPI\", page_icon=\"üõ∞Ô∏è\")\n",
        "st.title(\"Streamlit UI ‚Üí FastAPI /chat\")\n",
        "\n",
        "# --- Config ---\n",
        "# Read API URL from environment or use default localhost\n",
        "DEFAULT_API_URL = \"http://localhost:8000/chat\"\n",
        "API_URL = os.getenv(\"CHAT_API_URL\", DEFAULT_API_URL)\n",
        "\n",
        "# --- Session state ---\n",
        "if \"history\" not in st.session_state:\n",
        "    st.session_state.history = []  # [(role, text)]\n",
        "if \"thread_id\" not in st.session_state:\n",
        "    st.session_state.thread_id = \"demo-user-1\"\n",
        "\n",
        "# --- Input UI ---\n",
        "user_msg = st.text_input(\"Your message\", key=\"msg_input_api\")\n",
        "send = st.button(\"Send to API\")\n",
        "\n",
        "# --- Helper: call FastAPI /chat endpoint ---\n",
        "def call_api(message: str, thread_id: str | None = None) -> str:\n",
        "    \"\"\"Send POST request to FastAPI backend and return reply text.\"\"\"\n",
        "    payload = {\"message\": message}\n",
        "    if thread_id:\n",
        "        payload[\"thread_id\"] = thread_id\n",
        "    try:\n",
        "        r = requests.post(API_URL, json=payload, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        return data.get(\"reply\", \"(no reply field)\")\n",
        "    except Exception as e:\n",
        "        return f\"Error calling API: {e}\"\n",
        "\n",
        "# --- Handle Send button ---\n",
        "if send and user_msg.strip():\n",
        "    st.session_state.history.append((\"user\", user_msg))\n",
        "    with st.spinner(\"Contacting FastAPI backend...\"):\n",
        "        reply = call_api(user_msg, st.session_state.thread_id)\n",
        "    st.session_state.history.append((\"assistant\", reply))\n",
        "    # Trigger rerun for real-time update (compatible with old/new Streamlit)\n",
        "    if hasattr(st, \"rerun\"):\n",
        "        st.rerun()\n",
        "    elif hasattr(st, \"experimental_rerun\"):\n",
        "        st.experimental_rerun()\n",
        "\n",
        "# --- Display conversation ---\n",
        "st.subheader(\"Conversation\")\n",
        "for role, text in st.session_state.history:\n",
        "    st.markdown(f\"**{role.title()}:** {text}\")\n",
        "\n",
        "# --- Config panel ---\n",
        "with st.expander(\"Config\"):\n",
        "    st.write(\"API_URL:\", API_URL)\n",
        "    st.write(\"thread_id:\", st.session_state.thread_id)\n",
        "\n",
        "st.caption(\"Lightweight Streamlit UI. All LLM logic handled by FastAPI backend.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "269e49e2",
      "metadata": {},
      "source": [
        "## ‚ñ∂Ô∏è Run locally\n",
        "\n",
        "Start your **FastAPI backend** first:\n",
        "```bash\n",
        "uv run uvicorn main:app --reload --port 8000\n",
        "```\n",
        "\n",
        "Then, run the Streamlit UI:\n",
        "```bash\n",
        "uv run streamlit run app_streamlit.py\n",
        "```\n",
        "\n",
        "Visit [http://localhost:8501](http://localhost:8501) to chat with your model through the FastAPI endpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23eda2d1",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Troubleshooting\n",
        "\n",
        "- **Connection error:** Make sure FastAPI is running on port 8000.\n",
        "- **(no reply field):** Your backend didn‚Äôt return a `{\"reply\": ...}` response.\n",
        "- **Remote API:** To use a hosted backend, set an environment variable before launching Streamlit:\n",
        "```bash\n",
        "export CHAT_API_URL=\"https://myserver.com/chat\"\n",
        "uv run streamlit run app_streamlit.py\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b72db7e9",
      "metadata": {},
      "source": [
        "## ‚úÖ Summary\n",
        "\n",
        "- **Streamlit** builds fast, interactive UIs entirely in Python.\n",
        "- It pairs perfectly with **FastAPI** for a clean frontend-backend separation.\n",
        "- This setup scales naturally ‚Äî plug in LangGraph, CrewAI, or RAG systems behind `/chat`.\n",
        "- Keep Streamlit lightweight: just inputs, history, and visualization.\n",
        "\n",
        "üöÄ Next, you‚Äôll integrate **LangSmith monitoring** to track and debug your AI app end-to-end."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
